"""
Servicio de An√°lisis de Coherencia Individual
==============================================

Eval√∫a la coherencia de cada estudiante individualmente en exposiciones grupales.

Funcionalidades:
1. An√°lisis de coherencia con IA avanzada (Groq API) si est√° disponible
2. Fallback a an√°lisis sem√°ntico con Sentence Transformers
3. Detecci√≥n de palabras clave del tema
4. Evaluaci√≥n de profundidad del contenido
5. C√°lculo de calificaciones individuales ponderadas
6. Generaci√≥n de reportes individuales y grupales

Utiliza:
- Groq API (Llama 3.1 70B) para an√°lisis avanzado
- sentence-transformers para an√°lisis sem√°ntico (fallback)
- sklearn para c√°lculo de similitud
"""

try:
    from sentence_transformers import SentenceTransformer
    from sklearn.metrics.pairwise import cosine_similarity
    SENTENCE_TRANSFORMERS_AVAILABLE = True
except ImportError:
    SENTENCE_TRANSFORMERS_AVAILABLE = False
    print("‚ö†Ô∏è sentence-transformers no est√° instalado. El an√°lisis de coherencia estar√° limitado.")

import numpy as np
import logging
from django.conf import settings

logger = logging.getLogger(__name__)


class CoherenceAnalyzer:
    """
    Analizador de coherencia individual para exposiciones grupales
    
    Prioridad de an√°lisis:
    1. IA Avanzada (Groq) - Si est√° configurado GROQ_API_KEY
    2. Sentence Transformers - Fallback si no hay Groq
    3. An√°lisis b√°sico - √öltimo recurso
    """
    
    def __init__(self):
        """
        Inicializa el analizador con el modelo de embeddings y/o IA avanzada
        """
        # Intentar inicializar IA avanzada
        self.advanced_service = None
        if settings.USE_ADVANCED_COHERENCE:
            try:
                from .advanced_coherence_service import AdvancedCoherenceService
                self.advanced_service = AdvancedCoherenceService()
                logger.info("üöÄ IA Avanzada (Groq) activada para an√°lisis de coherencia")
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è No se pudo activar IA avanzada: {e}")
        
        # Inicializar modelo de embeddings como fallback
        if SENTENCE_TRANSFORMERS_AVAILABLE:
            try:
                # Modelo multiling√ºe optimizado para espa√±ol
                logger.info("ü§ñ Cargando modelo de an√°lisis sem√°ntico...")
                self.model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')
                self.model_loaded = True
                logger.info("‚úÖ Modelo cargado exitosamente")
            except Exception as e:
                logger.error(f"‚ùå Error cargando modelo: {str(e)}")
                self.model_loaded = False
        else:
            self.model_loaded = False
            logger.warning("‚ö†Ô∏è Modelo de an√°lisis sem√°ntico no disponible")
    
    def analizar_grupo(self, participaciones, tema, descripcion_tema="", max_score=20.0, assignment=None):
        """
        Analiza la coherencia de cada estudiante individualmente
        
        Usa IA avanzada (Groq) si est√° disponible, sino fallback a Sentence Transformers
        
        Args:
            participaciones: Lista de dict con estructura:
                [
                    {
                        'etiqueta': 'Persona 1',
                        'texto_transcrito': 'El cambio clim√°tico es...',
                        'tiempo_participacion': 120.5  # segundos
                    },
                    ...
                ]
            tema: Tema asignado de la exposici√≥n
            descripcion_tema: Descripci√≥n detallada del tema (instrucciones de la asignaci√≥n)
            max_score: Puntaje m√°ximo de la asignaci√≥n (default 20.0)
            assignment: Objeto Assignment completo (opcional, para configuraci√≥n de IA)
        
        Returns:
            Lista de resultados individuales con calificaciones
        """
        logger.info(f"üìä Analizando coherencia de {len(participaciones)} participantes (puntaje m√°ximo: {max_score})")
        
        # PRIORIDAD 1: IA Avanzada (Groq)
        if self.advanced_service:
            try:
                logger.info("üöÄ Usando IA Avanzada (Groq) para an√°lisis de coherencia")
                return self._analizar_con_ia_avanzada(participaciones, tema, descripcion_tema, max_score, assignment)
            except Exception as e:
                logger.error(f"‚ùå Error con IA avanzada: {e}. Usando fallback...")
        
        # PRIORIDAD 2: Sentence Transformers
        if not self.model_loaded:
            logger.warning("‚ö†Ô∏è Usando an√°lisis b√°sico por falta de modelo")
            return self._analizar_grupo_basico(participaciones, tema, descripcion_tema, max_score)
        
        # An√°lisis con Sentence Transformers (m√©todo original)
        logger.info("ü§ñ Usando Sentence Transformers para an√°lisis")
        
        resultados = []
        texto_tema = f"{tema}. {descripcion_tema}"
        
        try:
            # Generar embedding del tema una sola vez
            embedding_tema = self.model.encode([texto_tema])
            
            # Evaluar cada participante
            for idx, participacion in enumerate(participaciones, 1):
                logger.info(f"üîç Evaluando {participacion['etiqueta']}...")
                resultado_individual = self._evaluar_estudiante(
                    participacion,
                    embedding_tema,
                    tema,
                    descripcion_tema
                )
                resultados.append(resultado_individual)
            
            # Calcular calificaciones finales proporcionales
            resultados = self._calcular_calificaciones_finales(resultados, max_score)
            
            logger.info(f"‚úÖ An√°lisis completado para {len(resultados)} participantes")
            
        except Exception as e:
            logger.error(f"‚ùå Error en an√°lisis de grupo: {str(e)}", exc_info=True)
            return self._analizar_grupo_basico(participaciones, tema, descripcion_tema, max_score)
        
        return resultados
    
    def _evaluar_estudiante(self, participacion, embedding_tema, tema, descripcion_tema):
        """Eval√∫a coherencia de un estudiante individual"""
        texto = participacion['texto_transcrito']
        etiqueta = participacion['etiqueta']
        
        # Validar texto m√≠nimo
        if len(texto.strip()) < 20:
            return self._resultado_sin_contenido(participacion)
        
        try:
            # 1. COHERENCIA SEM√ÅNTICA (60% de la nota)
            coherencia_semantica = self._calcular_coherencia_semantica(texto, embedding_tema)
            
            # 2. PALABRAS CLAVE (20% de la nota)
            palabras_clave = self._analizar_palabras_clave(texto, tema, descripcion_tema)
            puntaje_palabras = palabras_clave['puntaje']
            
            # 3. LONGITUD Y PROFUNDIDAD (20% de la nota)
            puntaje_profundidad = self._analizar_profundidad(texto)
            
            # CALIFICACI√ìN PONDERADA (sobre 100)
            nota_coherencia = (
                coherencia_semantica * 0.60 +  # 60%
                puntaje_palabras * 0.20 +       # 20%
                puntaje_profundidad * 0.20      # 20%
            )
            
            # Determinar nivel y observaci√≥n (provisional, se recalcular√° despu√©s)
            nivel, observacion = self._clasificar_coherencia(nota_coherencia, coherencia_semantica)
            
            return {
                'etiqueta': etiqueta,
                'tiempo_participacion': participacion['tiempo_participacion'],
                'texto_transcrito': texto,
                'coherencia_semantica': round(coherencia_semantica, 2),
                'palabras_clave_encontradas': palabras_clave['palabras'],
                'puntaje_palabras_clave': round(puntaje_palabras, 2),
                'puntaje_profundidad': round(puntaje_profundidad, 2),
                'nota_coherencia': round(nota_coherencia, 2),
                'nivel': nivel,  # Se recalcular√° en _calcular_calificaciones_finales
                'observacion': observacion,
                'palabras_totales': len(texto.split()),
                'caracteres': len(texto),
                'foto_url': participacion.get('foto_url')  # Incluir URL de la foto
            }
            
        except Exception as e:
            logger.error(f"‚ùå Error evaluando {etiqueta}: {str(e)}")
            return self._resultado_error(participacion)
    
    def _calcular_coherencia_semantica(self, texto, embedding_tema):
        """Calcula similitud sem√°ntica entre texto y tema"""
        embedding_estudiante = self.model.encode([texto])
        similitud = cosine_similarity(embedding_estudiante, embedding_tema)[0][0]
        
        # Convertir a porcentaje (0-100)
        # Ajustar para que valores t√≠picos (0.3-0.8) mapeen mejor a 0-100
        coherencia = float(similitud * 125)  # Factor de ajuste
        coherencia = min(100, max(0, coherencia))  # Limitar a 0-100
        
        return coherencia
    
    def _analizar_palabras_clave(self, texto, tema, descripcion):
        """Detecta palabras clave del tema en el texto del estudiante"""
        # Combinar tema y descripci√≥n para extraer m√°s palabras clave
        texto_completo_tema = f"{tema} {descripcion}".lower()
        palabras_tema = set(texto_completo_tema.split())
        palabras_texto = set(texto.lower().split())
        
        # Filtrar palabras comunes sin valor (stop words)
        palabras_comunes = {
            'el', 'la', 'los', 'las', 'un', 'una', 'unos', 'unas',
            'de', 'en', 'y', 'o', 'pero', 'por', 'para', 'con',
            'a', 'al', 'del', 'es', 'son', 'est√°', 'est√°n',
            'que', 'cual', 'como', 'se', 'su', 'sus', 'mi', 'tu',
            'te', 'me', 'le', 'les', 'nos', 'lo', 'este', 'esta'
        }
        palabras_tema = palabras_tema - palabras_comunes
        
        # Filtrar palabras muy cortas (menos de 4 letras)
        palabras_tema = {p for p in palabras_tema if len(p) >= 4}
        
        # Encontrar coincidencias
        palabras_encontradas = list(palabras_tema.intersection(palabras_texto))
        
        # Calcular puntaje
        if len(palabras_tema) > 0:
            porcentaje = (len(palabras_encontradas) / len(palabras_tema)) * 100
            # Puntaje: 100 si encuentra al menos 40% de palabras clave
            puntaje = min(porcentaje * 2.5, 100)
        else:
            puntaje = 50  # Puntaje neutral si no hay palabras clave
        
        return {
            'palabras': palabras_encontradas[:10],  # Limitar a 10 para display
            'puntaje': puntaje,
            'total_encontradas': len(palabras_encontradas),
            'total_tema': len(palabras_tema)
        }
    
    def _analizar_profundidad(self, texto):
        """Eval√∫a la profundidad del contenido basado en longitud y estructura"""
        palabras = texto.split()
        num_palabras = len(palabras)
        
        # Palabras indicadoras de profundidad y an√°lisis
        indicadores_profundidad = [
            'porque', 'debido', 'causa', 'consecuencia', 'resultado',
            'ejemplo', 'como', 'adem√°s', 'tambi√©n', 'sin embargo',
            'por lo tanto', 'en conclusi√≥n', 'finalmente', 'as√≠',
            'entonces', 'espec√≠ficamente', 'particularmente',
            'significa', 'implica', 'demuestra', 'evidencia',
            'importante', 'fundamental', 'esencial', 'clave',
            'primero', 'segundo', 'tercero', 'finalmente'
        ]
        
        texto_lower = texto.lower()
        indicadores_encontrados = sum(
            1 for indicador in indicadores_profundidad 
            if indicador in texto_lower
        )
        
        # Puntaje basado en palabras (30-50% del total)
        if num_palabras < 20:
            puntaje_base = 10
        elif num_palabras < 40:
            puntaje_base = 30
        elif num_palabras < 80:
            puntaje_base = 50
        elif num_palabras < 150:
            puntaje_base = 70
        else:
            puntaje_base = 85
        
        # Bonus por uso de conectores y palabras de an√°lisis (hasta 30% adicional)
        bonus_conectores = min(indicadores_encontrados * 3, 15)
        
        # Bonus por longitud de oraciones (se√±al de elaboraci√≥n)
        oraciones = texto.count('.') + texto.count('?') + texto.count('!')
        if oraciones > 0:
            palabras_por_oracion = num_palabras / oraciones
            if 10 <= palabras_por_oracion <= 25:  # Rango ideal
                bonus_oraciones = 5
            else:
                bonus_oraciones = 0
        else:
            bonus_oraciones = 0
        
        puntaje_total = min(puntaje_base + bonus_conectores + bonus_oraciones, 100)
        
        return puntaje_total
    
    def _clasificar_coherencia(self, nota_coherencia, coherencia_semantica):
        """Determina nivel y observaci√≥n seg√∫n el puntaje"""
        if nota_coherencia >= 80:
            nivel = "Excelente"
            observacion = "Discurso altamente coherente y bien estructurado con el tema asignado"
        elif nota_coherencia >= 70:
            nivel = "Muy Buena"
            observacion = "Muy buena relaci√≥n con el tema, aborda los puntos principales"
        elif nota_coherencia >= 60:
            nivel = "Buena"
            observacion = "Buena coherencia con el tema, cubre aspectos relevantes"
        elif nota_coherencia >= 50:
            nivel = "Regular"
            observacion = "Coherencia moderada, se desv√≠a parcialmente del tema"
        elif nota_coherencia >= 40:
            nivel = "Baja"
            observacion = "Poca coherencia con el tema asignado, varios desv√≠os"
        else:
            nivel = "Insuficiente"
            observacion = "Contenido insuficiente o muy poco relacionado con el tema"
        
        return nivel, observacion
    
    def _calcular_calificaciones_finales(self, resultados, max_score=20.0):
        """
        Calcula el porcentaje de aporte de cada estudiante
        considerando tiempo Y coherencia
        """
        logger.info(f"üìä Calculando calificaciones finales con max_score={max_score}")
        
        # Calcular tiempo total
        tiempo_total = sum(r['tiempo_participacion'] for r in resultados)
        
        if tiempo_total == 0:
            logger.warning("‚ö†Ô∏è Tiempo total es 0, asignando valores predeterminados")
            for r in resultados:
                r['porcentaje_tiempo'] = 0
                r['porcentaje_aporte'] = 0
                r['calificacion_final'] = 0
            return resultados
        
        for resultado in resultados:
            # Porcentaje de tiempo
            porcentaje_tiempo = (resultado['tiempo_participacion'] / tiempo_total) * 100
            resultado['porcentaje_tiempo'] = round(porcentaje_tiempo, 2)
            
            # Porcentaje de aporte = tiempo √ó factor_coherencia
            # Si habl√≥ 33% del tiempo con 80% de coherencia ‚Üí aporte ajustado
            factor_coherencia = resultado['nota_coherencia'] / 100
            aporte_ponderado = porcentaje_tiempo * factor_coherencia
            
            resultado['porcentaje_aporte'] = round(aporte_ponderado, 2)
            
            # Calificaci√≥n final sobre max_score (din√°mico seg√∫n configuraci√≥n de asignaci√≥n)
            # Basada en coherencia ajustada por participaci√≥n m√≠nima
            if porcentaje_tiempo < 15:  # Menos del 15% es penalizado
                factor_penalizacion = porcentaje_tiempo / 15
            else:
                factor_penalizacion = 1.0
            
            calificacion = (resultado['nota_coherencia'] / 100) * max_score * factor_penalizacion
            resultado['calificacion_final'] = round(calificacion, 2)
            resultado['max_score'] = max_score  # Guardar max_score en el resultado
            
            # Recalcular nivel bas√°ndose en la calificaci√≥n final (porcentaje sobre max_score)
            porcentaje_calificacion = (resultado['calificacion_final'] / max_score) * 100
            
            # LOG DETALLADO PARA DEBUG
            logger.info(f"üîç DEBUG - {resultado['etiqueta']}: calificacion_final={resultado['calificacion_final']}, max_score={max_score}, porcentaje={porcentaje_calificacion:.2f}%")
            
            if porcentaje_calificacion >= 90:
                resultado['nivel'] = "Excelente"
                logger.info(f"  ‚úÖ Nivel asignado: Excelente (>= 90%)")
            elif porcentaje_calificacion >= 80:
                resultado['nivel'] = "Muy Buena"
                logger.info(f"  ‚úÖ Nivel asignado: Muy Buena (>= 80%)")
            elif porcentaje_calificacion >= 70:
                resultado['nivel'] = "Buena"
                logger.info(f"  ‚úÖ Nivel asignado: Buena (>= 70%)")
            elif porcentaje_calificacion >= 60:
                resultado['nivel'] = "Regular"
                logger.info(f"  ‚úÖ Nivel asignado: Regular (>= 60%)")
            elif porcentaje_calificacion >= 50:
                resultado['nivel'] = "Baja"
                logger.info(f"  ‚ö†Ô∏è Nivel asignado: Baja (>= 50%)")
            else:
                resultado['nivel'] = "Insuficiente"
                logger.info(f"  ‚ùå Nivel asignado: Insuficiente (< 50%)")
        
        # Normalizar porcentajes de aporte para que sumen 100%
        suma_aportes = sum(r['porcentaje_aporte'] for r in resultados)
        if suma_aportes > 0:
            for resultado in resultados:
                resultado['porcentaje_aporte_normalizado'] = round(
                    (resultado['porcentaje_aporte'] / suma_aportes) * 100, 2
                )
        else:
            for resultado in resultados:
                resultado['porcentaje_aporte_normalizado'] = 0
        
        return resultados
    
    def _analizar_grupo_basico(self, participaciones, tema, descripcion_tema, max_score=20.0):
        """An√°lisis b√°sico sin modelo de embeddings (fallback)"""
        logger.info("üìä Usando an√°lisis b√°sico de coherencia")
        
        resultados = []
        for participacion in participaciones:
            texto = participacion['texto_transcrito']
            
            # An√°lisis b√°sico por palabras clave
            palabras_clave = self._analizar_palabras_clave(texto, tema, descripcion_tema)
            puntaje_palabras = palabras_clave['puntaje']
            
            # An√°lisis de profundidad
            puntaje_profundidad = self._analizar_profundidad(texto)
            
            # Puntaje combinado (sin similitud sem√°ntica)
            nota_coherencia = (puntaje_palabras * 0.6 + puntaje_profundidad * 0.4)
            
            nivel, observacion = self._clasificar_coherencia(nota_coherencia, puntaje_palabras)
            
            resultados.append({
                'etiqueta': participacion['etiqueta'],
                'tiempo_participacion': participacion['tiempo_participacion'],
                'texto_transcrito': texto,
                'coherencia_semantica': puntaje_palabras,
                'palabras_clave_encontradas': palabras_clave['palabras'],
                'puntaje_palabras_clave': round(puntaje_palabras, 2),
                'puntaje_profundidad': round(puntaje_profundidad, 2),
                'nota_coherencia': round(nota_coherencia, 2),
                'nivel': nivel,
                'observacion': observacion + " (an√°lisis b√°sico)",
                'palabras_totales': len(texto.split()),
                'caracteres': len(texto)
            })
        
        return self._calcular_calificaciones_finales(resultados, max_score)
    
    def _resultado_sin_contenido(self, participacion):
        """Resultado para participante sin contenido suficiente"""
        return {
            'etiqueta': participacion['etiqueta'],
            'tiempo_participacion': participacion['tiempo_participacion'],
            'texto_transcrito': participacion['texto_transcrito'],
            'coherencia_semantica': 0,
            'palabras_clave_encontradas': [],
            'puntaje_palabras_clave': 0,
            'puntaje_profundidad': 0,
            'nota_coherencia': 0,
            'nivel': "Insuficiente",
            'observacion': "Participaci√≥n muy breve o sin contenido relevante",
            'palabras_totales': len(participacion['texto_transcrito'].split()),
            'caracteres': len(participacion['texto_transcrito'])
        }
    
    def _resultado_error(self, participacion):
        """Resultado en caso de error de procesamiento"""
        return {
            'etiqueta': participacion['etiqueta'],
            'tiempo_participacion': participacion['tiempo_participacion'],
            'texto_transcrito': participacion['texto_transcrito'],
            'coherencia_semantica': 0,
            'palabras_clave_encontradas': [],
            'puntaje_palabras_clave': 0,
            'puntaje_profundidad': 0,
            'nota_coherencia': 0,
            'nivel': "Error",
            'observacion': "Error al procesar la participaci√≥n",
            'palabras_totales': 0,
            'caracteres': 0
        }
    
    def generar_resumen_grupal(self, resultados):
        """
        Genera un resumen textual del an√°lisis grupal
        
        Args:
            resultados: Lista de resultados individuales
        
        Returns:
            str: Resumen formateado en texto
        """
        if not resultados:
            return "No hay resultados para mostrar."
        
        resumen = f"üìä **EVALUACI√ìN GRUPAL - {len(resultados)} Participantes**\n\n"
        
        # Ordenar por calificaci√≥n (mayor a menor)
        resultados_ordenados = sorted(resultados, key=lambda x: x['calificacion_final'], reverse=True)
        
        for idx, r in enumerate(resultados_ordenados, 1):
            max_score_individual = r.get('max_score', 20.0)
            resumen += f"**{idx}. {r['etiqueta']}**\n"
            resumen += f"   üìù Calificaci√≥n: {r['calificacion_final']}/{max_score_individual} ({r['nivel']})\n"
            resumen += f"   ‚è±Ô∏è  Tiempo: {r['porcentaje_tiempo']:.1f}%\n"
            resumen += f"   üìà Aporte: {r['porcentaje_aporte_normalizado']:.1f}%\n"
            resumen += f"   üéØ Coherencia: {r['nota_coherencia']:.1f}/100\n"
            resumen += f"   üí¨ {r['palabras_totales']} palabras\n\n"
        
        # Estad√≠sticas generales
        promedio_coherencia = np.mean([r['nota_coherencia'] for r in resultados])
        promedio_calificacion = np.mean([r['calificacion_final'] for r in resultados])
        max_score_value = resultados[0].get('max_score', 20.0) if resultados else 20.0
        
        resumen += f"**üìä Estad√≠sticas del Grupo:**\n"
        resumen += f"   ‚Ä¢ Coherencia promedio: {promedio_coherencia:.1f}/100\n"
        resumen += f"   ‚Ä¢ Calificaci√≥n promedio: {promedio_calificacion:.1f}/{max_score_value}\n"
        
        # An√°lisis de equidad
        desviacion_tiempo = np.std([r['porcentaje_tiempo'] for r in resultados])
        if desviacion_tiempo < 10:
            resumen += f"   ‚Ä¢ ‚úÖ Participaci√≥n muy equilibrada\n"
        elif desviacion_tiempo < 20:
            resumen += f"   ‚Ä¢ ‚ö†Ô∏è  Participaci√≥n moderadamente equilibrada\n"
        else:
            resumen += f"   ‚Ä¢ ‚ùå Participaci√≥n desigual\n"
        
        return resumen

    def _analizar_con_ia_avanzada(self, participaciones, tema, descripcion_tema, max_score=20.0, assignment=None):
        """
        Analiza coherencia usando IA avanzada (Groq API)
        
        Este m√©todo utiliza Llama 3.3 70B para an√°lisis sem√°ntico profundo
        
        Args:
            assignment: Objeto Assignment para obtener configuraci√≥n de estrictez
        """
        logger.info(f"üìä An√°lisis con IA avanzada - max_score={max_score}")
        resultados = []
        
        for participacion in participaciones:
            etiqueta = participacion['etiqueta']
            texto = participacion['texto_transcrito']
            tiempo = participacion['tiempo_participacion']
            
            logger.info(f"ü§ñ Analizando {etiqueta} con IA avanzada...")
            
            try:
                # Llamar al servicio de IA avanzada con assignment para configuraci√≥n
                ai_result = self.advanced_service.analyze_participant_coherence(
                    participant_name=etiqueta,
                    transcribed_text=texto,
                    assignment_title=tema,
                    assignment_description=descripcion_tema,
                    assignment=assignment
                )
                
                # Convertir score de 0-100 a nota de 0-max_score (din√°mico seg√∫n asignaci√≥n)
                coherence_score = ai_result['coherence_score']  # 0-100
                nota_sobre_max = (coherence_score / 100) * max_score  # 0-max_score
                
                # Construir resultado compatible con el formato existente
                resultado = {
                    'etiqueta': etiqueta,
                    'texto_transcrito': texto,
                    'nota_coherencia': coherence_score,  # 0-100
                    'calificacion_final': round(nota_sobre_max, 2),  # 0-max_score
                    'nivel': self._clasificar_nivel(nota_sobre_max),
                    'observacion': ai_result['feedback'][:200] + '...' if len(ai_result['feedback']) > 200 else ai_result['feedback'],  # Resumen corto
                    'feedback_ia_avanzada': ai_result['feedback'],  # Feedback completo de IA
                    'palabras_totales': len(texto.split()),
                    'tiempo_participacion': tiempo,
                    'porcentaje_tiempo': 0,  # Se calcula despu√©s
                    'porcentaje_aporte_normalizado': 0,  # Se calcula despu√©s
                    
                    # Compatibilidad con campos existentes
                    'coherencia_semantica': coherence_score,
                    'palabras_clave_encontradas': ai_result.get('key_concepts_covered', []),
                    'puntaje_palabras_clave': coherence_score,  # Aproximaci√≥n
                    'puntaje_profundidad': coherence_score,  # Aproximaci√≥n
                    'foto_url': participacion.get('foto_url'),
                    
                    # Detalles de IA avanzada
                    'ai_powered': True,
                    'details': ai_result['details'],
                    'strengths': ai_result.get('strengths', []),
                    'improvements': ai_result.get('improvements', []),
                    'key_concepts_covered': ai_result.get('key_concepts_covered', []),
                    'missing_elements': ai_result.get('missing_elements', [])
                }
                
                resultados.append(resultado)
                logger.info(f"‚úÖ {etiqueta}: {coherence_score:.1f}% coherencia")
                
            except Exception as e:
                logger.error(f"‚ùå Error analizando {etiqueta} con IA: {e}")
                # Fallback a an√°lisis b√°sico para este participante
                resultado_basico = self._analizar_participante_basico(
                    participacion, tema, descripcion_tema
                )
                resultados.append(resultado_basico)
        
        # Calcular porcentajes relativos
        if resultados:
            tiempo_total = sum(r['tiempo_participacion'] for r in resultados)
            for resultado in resultados:
                resultado['porcentaje_tiempo'] = (
                    (resultado['tiempo_participacion'] / tiempo_total * 100) 
                    if tiempo_total > 0 else 0
                )
                resultado['porcentaje_aporte_normalizado'] = resultado['porcentaje_tiempo']
        
        return resultados
    
    def _clasificar_nivel(self, nota):
        """Clasifica el nivel de desempe√±o seg√∫n la nota (0-20)"""
        if nota >= 18:
            return "Excelente"
        elif nota >= 15:
            return "Muy Bueno"
        elif nota >= 13:
            return "Bueno"
        elif nota >= 11:
            return "Regular"
        else:
            return "Insuficiente"
    
    def _analizar_participante_basico(self, participacion, tema, descripcion_tema):
        """An√°lisis b√°sico de un participante (fallback)"""
        etiqueta = participacion['etiqueta']
        texto = participacion['texto_transcrito']
        tiempo = participacion['tiempo_participacion']
        
        # An√°lisis muy b√°sico basado en longitud y palabras clave
        palabras = texto.lower().split()
        palabras_tema = tema.lower().split()
        
        coincidencias = sum(1 for p in palabras if p in palabras_tema)
        coherencia_basica = min(100, (coincidencias / max(len(palabras_tema), 1)) * 100)
        
        nota_20 = (coherencia_basica / 100) * 20
        
        return {
            'etiqueta': etiqueta,
            'nota_coherencia': coherencia_basica,
            'calificacion_final': round(nota_20, 2),
            'nivel': self._clasificar_nivel(nota_20),
            'feedback': f"An√°lisis b√°sico: {coincidencias} coincidencias con el tema.",
            'palabras_totales': len(palabras),
            'tiempo_participacion': tiempo,
            'porcentaje_tiempo': 0,
            'porcentaje_aporte_normalizado': 0,
            'ai_powered': False
        }

    def generar_conclusion_grupal(self, resultados_participantes, tema, descripcion_tema, max_score=20.0):
        """
        Genera una conclusi√≥n grupal personalizada usando IA de GROQ
        
        Args:
            resultados_participantes: Lista de resultados de an√°lisis individual
            tema: T√≠tulo del tema
            descripcion_tema: Descripci√≥n detallada del tema
            max_score: Puntaje m√°ximo de la asignaci√≥n (default: 20.0)
            
        Returns:
            str: Conclusi√≥n grupal generada por IA o mensaje predeterminado
        """
        if not resultados_participantes:
            return "No se encontraron participantes para analizar."
        
        try:
            # Intentar usar GROQ para generar conclusi√≥n din√°mica
            from apps.ai_processor.services.groq_key_manager import GroqKeyManager
            from groq import Groq
            
            key_manager = GroqKeyManager()
            groq_api_key = key_manager.get_current_key()
            
            if not groq_api_key:
                logger.warning("No hay API key de GROQ disponible, usando conclusi√≥n b√°sica")
                return self._generar_conclusion_basica(resultados_participantes)
            
            # Preparar datos del grupo para el prompt
            num_participantes = len(resultados_participantes)
            coherencia_promedio = np.mean([r['nota_coherencia'] for r in resultados_participantes])
            calificacion_promedio = np.mean([r['calificacion_final'] for r in resultados_participantes])
            
            # Informaci√≥n de cada participante
            info_participantes = []
            for idx, r in enumerate(resultados_participantes, 1):
                info_participantes.append(
                    f"{idx}. {r['etiqueta']}: {r['calificacion_final']:.1f}/{max_score} pts "
                    f"(Coherencia: {r['nota_coherencia']:.1f}%, Tiempo: {r['porcentaje_tiempo']:.1f}%)"
                )
            
            participantes_texto = "\n".join(info_participantes)
            
            # Identificar puntos fuertes y d√©biles
            mejor_participante = max(resultados_participantes, key=lambda x: x['calificacion_final'])
            peor_participante = min(resultados_participantes, key=lambda x: x['calificacion_final'])
            participante_mas_tiempo = max(resultados_participantes, key=lambda x: x['porcentaje_tiempo'])
            
            # Calcular desviaci√≥n est√°ndar de coherencia para ver dispersi√≥n
            coherencias = [r['nota_coherencia'] for r in resultados_participantes]
            desviacion_coherencia = np.std(coherencias)
            
            # Determinar si la coherencia es baja, media o alta
            if coherencia_promedio < 50:
                nivel_comprension = "BAJA - El grupo NO logr√≥ demostrar comprensi√≥n adecuada del tema"
            elif coherencia_promedio < 70:
                nivel_comprension = "MEDIA - El grupo demostr√≥ comprensi√≥n parcial del tema"
            else:
                nivel_comprension = "ALTA - El grupo demostr√≥ buena comprensi√≥n del tema"
            
            # Analizar equilibrio de participaci√≥n
            tiempos = [r['porcentaje_tiempo'] for r in resultados_participantes]
            desviacion_tiempo = np.std(tiempos)
            if desviacion_tiempo > 20:
                equilibrio_participacion = "DESIGUAL - Hay gran diferencia en el tiempo de participaci√≥n"
            elif desviacion_tiempo > 10:
                equilibrio_participacion = "MODERADO - La participaci√≥n est√° medianamente equilibrada"
            else:
                equilibrio_participacion = "EQUILIBRADO - Todos participaron de forma similar"
            
            # Construir prompt para GROQ con an√°lisis cr√≠tico
            prompt = f"""Eres un evaluador acad√©mico OBJETIVO y CR√çTICO que analiza presentaciones grupales. Debes generar una conclusi√≥n REALISTA basada en las m√©tricas.

**Tema asignado:** {tema}

**Descripci√≥n completa:** {descripcion_tema[:300]}

**Resultados de cada participante ({num_participantes}):**
{participantes_texto}

**AN√ÅLISIS CR√çTICO:**
- Coherencia promedio: {coherencia_promedio:.1f}% ‚Üí {nivel_comprension}
- Calificaci√≥n promedio: {calificacion_promedio:.1f}/{max_score}
- Dispersi√≥n en coherencia: {desviacion_coherencia:.1f}% ({"Alta variabilidad" if desviacion_coherencia > 15 else "Moderada" if desviacion_coherencia > 8 else "Baja variabilidad"})
- Distribuci√≥n de tiempo: {equilibrio_participacion}
- Mejor participante: {mejor_participante['etiqueta']} ({mejor_participante['nota_coherencia']:.1f}% coherencia)
- Participante m√°s d√©bil: {peor_participante['etiqueta']} ({peor_participante['nota_coherencia']:.1f}% coherencia)

**INSTRUCCIONES IMPORTANTES:**
1. Si la coherencia promedio es MENOR a 50%, di claramente que el grupo NO cumpli√≥ adecuadamente con el tema
2. Si la coherencia promedio es 50-69%, di que cumplieron PARCIALMENTE pero necesitan mejorar
3. Si la coherencia promedio es 70% o m√°s, di que cumplieron bien
4. S√© ESPEC√çFICO sobre qu√© aspectos fallaron o destacaron
5. Si hay gran variabilidad (desviaci√≥n >15%), menciona que algunos participantes estuvieron mejor que otros
6. Si la participaci√≥n es muy desigual (desviaci√≥n tiempo >20%), se√±√°lalo como √°rea cr√≠tica de mejora
7. NO uses frases gen√©ricas como "comprensi√≥n b√°sica" cuando los datos muestran bajo rendimiento
8. M√°ximo 3-4 oraciones, directas y constructivas

Genera SOLO la conclusi√≥n grupal, sin t√≠tulos ni formato adicional:"""

            client = Groq(api_key=groq_api_key)
            
            response = client.chat.completions.create(
                model="llama-3.3-70b-versatile",
                messages=[
                    {
                        "role": "system",
                        "content": """Eres un evaluador acad√©mico EXPERTO y OBJETIVO. Tu trabajo es dar retroalimentaci√≥n REALISTA basada en m√©tricas concretas.

REGLAS IMPORTANTES:
- Si los datos muestran bajo rendimiento, s√© HONESTO al se√±alarlo
- NO uses eufemismos vagos como "comprensi√≥n b√°sica" cuando la coherencia es menor a 50%
- S√© ESPEC√çFICO: menciona qu√© fall√≥ y qu√© se puede mejorar
- Mant√©n un tono profesional pero directo
- La retroalimentaci√≥n debe ser CONSTRUCTIVA pero REALISTA
- NO infles los logros si las m√©tricas no los respaldan"""
                    },
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                temperature=0.6,  # Reducido para respuestas m√°s consistentes y objetivas
                max_tokens=300,   # Aumentado para conclusiones m√°s detalladas
                top_p=0.9,
                stream=False
            )
            
            conclusion = response.choices[0].message.content.strip()
            
            # Verificar que la conclusi√≥n no est√© vac√≠a
            if conclusion and len(conclusion) > 20:
                logger.info(f"‚úÖ Conclusi√≥n grupal generada con GROQ ({len(conclusion)} caracteres)")
                return conclusion
            else:
                logger.warning("Conclusi√≥n de GROQ muy corta, usando b√°sica")
                return self._generar_conclusion_basica(resultados_participantes)
                
        except Exception as e:
            logger.error(f"Error al generar conclusi√≥n con GROQ: {str(e)}")
            return self._generar_conclusion_basica(resultados_participantes)
    
    def _generar_conclusion_basica(self, resultados_participantes):
        """
        Genera una conclusi√≥n b√°sica cuando GROQ no est√° disponible
        """
        if not resultados_participantes:
            return "No hay participantes para evaluar."
        
        coherencia_promedio = np.mean([r['nota_coherencia'] for r in resultados_participantes])
        calificacion_promedio = np.mean([r['calificacion_final'] for r in resultados_participantes])
        num_participantes = len(resultados_participantes)
        
        # An√°lisis de dispersi√≥n
        coherencias = [r['nota_coherencia'] for r in resultados_participantes]
        desviacion_coherencia = np.std(coherencias)
        
        # An√°lisis de equilibrio de tiempo
        tiempos = [r['porcentaje_tiempo'] for r in resultados_participantes]
        desviacion_tiempo = np.std(tiempos)
        
        # Generar conclusi√≥n basada en m√©tricas reales
        if coherencia_promedio >= 80:
            conclusion = f"El grupo ({num_participantes} participantes) demostr√≥ excelente dominio del tema con {coherencia_promedio:.1f}% de coherencia promedio. "
            if desviacion_coherencia < 10:
                conclusion += "Todos los integrantes mantuvieron un nivel consistentemente alto. "
            else:
                conclusion += "Aunque algunos participantes destacaron m√°s que otros, el nivel general fue sobresaliente. "
            conclusion += "Se recomienda mantener este nivel de preparaci√≥n y profundizaci√≥n tem√°tica."
            
        elif coherencia_promedio >= 70:
            conclusion = f"El grupo logr√≥ cumplir adecuadamente con el tema asignado, alcanzando {coherencia_promedio:.1f}% de coherencia promedio. "
            if desviacion_coherencia > 15:
                conclusion += "Sin embargo, se observa variabilidad significativa entre participantes, lo que sugiere preparaci√≥n desigual. "
            conclusion += "Se sugiere profundizar m√°s en los conceptos clave y asegurar que todos los integrantes dominen el tema de forma equilibrada."
            
        elif coherencia_promedio >= 50:
            conclusion = f"El grupo cumpli√≥ parcialmente con el tema, obteniendo {coherencia_promedio:.1f}% de coherencia promedio. "
            if calificacion_promedio < 12:
                conclusion += "Las calificaciones individuales reflejan que varios participantes no lograron desarrollar el tema con suficiente profundidad. "
            if desviacion_tiempo > 20:
                conclusion += "Adem√°s, la participaci√≥n fue muy desigual, lo cual afect√≥ el desempe√±o grupal. "
            conclusion += "Se recomienda mejorar la preparaci√≥n tem√°tica, estructurar mejor el contenido y equilibrar la participaci√≥n de todos los miembros."
            
        else:
            conclusion = f"El grupo NO logr√≥ cumplir adecuadamente con el tema asignado, alcanzando solo {coherencia_promedio:.1f}% de coherencia promedio. "
            conclusion += "Los an√°lisis individuales muestran falta de comprensi√≥n de los conceptos fundamentales y desarrollo insuficiente del contenido. "
            if desviacion_coherencia > 15:
                conclusion += "La gran variabilidad entre participantes indica preparaci√≥n muy desigual. "
            conclusion += "Es cr√≠tico revisar los conceptos b√°sicos del tema, mejorar la preparaci√≥n grupal y asegurar que todos los integrantes comprendan y puedan explicar los puntos clave antes de la presentaci√≥n."
        
        return conclusion
