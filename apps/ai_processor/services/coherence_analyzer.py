"""
Servicio de An√°lisis de Coherencia Individual
==============================================

Eval√∫a la coherencia de cada estudiante individualmente en exposiciones grupales.

Funcionalidades:
1. An√°lisis de coherencia con IA avanzada (Groq API) si est√° disponible
2. Fallback a an√°lisis sem√°ntico con Sentence Transformers
3. Detecci√≥n de palabras clave del tema
4. Evaluaci√≥n de profundidad del contenido
5. C√°lculo de calificaciones individuales ponderadas
6. Generaci√≥n de reportes individuales y grupales

Utiliza:
- Groq API (Llama 3.1 70B) para an√°lisis avanzado
- sentence-transformers para an√°lisis sem√°ntico (fallback)
- sklearn para c√°lculo de similitud
"""

try:
    from sentence_transformers import SentenceTransformer
    from sklearn.metrics.pairwise import cosine_similarity
    SENTENCE_TRANSFORMERS_AVAILABLE = True
except ImportError:
    SENTENCE_TRANSFORMERS_AVAILABLE = False
    print("‚ö†Ô∏è sentence-transformers no est√° instalado. El an√°lisis de coherencia estar√° limitado.")

import numpy as np
import logging
from django.conf import settings

logger = logging.getLogger(__name__)


class CoherenceAnalyzer:
    """
    Analizador de coherencia individual para exposiciones grupales
    
    Prioridad de an√°lisis:
    1. IA Avanzada (Groq) - Si est√° configurado GROQ_API_KEY
    2. Sentence Transformers - Fallback si no hay Groq
    3. An√°lisis b√°sico - √öltimo recurso
    """
    
    def __init__(self):
        """
        Inicializa el analizador con el modelo de embeddings y/o IA avanzada
        """
        # Intentar inicializar IA avanzada
        self.advanced_service = None
        if settings.USE_ADVANCED_COHERENCE:
            try:
                from .advanced_coherence_service import AdvancedCoherenceService
                self.advanced_service = AdvancedCoherenceService()
                logger.info("üöÄ IA Avanzada (Groq) activada para an√°lisis de coherencia")
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è No se pudo activar IA avanzada: {e}")
        
        # Inicializar modelo de embeddings como fallback
        if SENTENCE_TRANSFORMERS_AVAILABLE:
            try:
                # Modelo multiling√ºe optimizado para espa√±ol
                logger.info("ü§ñ Cargando modelo de an√°lisis sem√°ntico...")
                self.model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')
                self.model_loaded = True
                logger.info("‚úÖ Modelo cargado exitosamente")
            except Exception as e:
                logger.error(f"‚ùå Error cargando modelo: {str(e)}")
                self.model_loaded = False
        else:
            self.model_loaded = False
            logger.warning("‚ö†Ô∏è Modelo de an√°lisis sem√°ntico no disponible")
    
    def analizar_grupo(self, participaciones, tema, descripcion_tema="", max_score=20.0):
        """
        Analiza la coherencia de cada estudiante individualmente
        
        Usa IA avanzada (Groq) si est√° disponible, sino fallback a Sentence Transformers
        
        Args:
            participaciones: Lista de dict con estructura:
                [
                    {
                        'etiqueta': 'Persona 1',
                        'texto_transcrito': 'El cambio clim√°tico es...',
                        'tiempo_participacion': 120.5  # segundos
                    },
                    ...
                ]
            tema: Tema asignado de la exposici√≥n
            descripcion_tema: Descripci√≥n detallada del tema (instrucciones de la asignaci√≥n)
            max_score: Puntaje m√°ximo de la asignaci√≥n (default 20.0)
        
        Returns:
            Lista de resultados individuales con calificaciones
        """
        logger.info(f"üìä Analizando coherencia de {len(participaciones)} participantes (puntaje m√°ximo: {max_score})")
        
        # PRIORIDAD 1: IA Avanzada (Groq)
        if self.advanced_service:
            try:
                logger.info("üöÄ Usando IA Avanzada (Groq) para an√°lisis de coherencia")
                return self._analizar_con_ia_avanzada(participaciones, tema, descripcion_tema, max_score)
            except Exception as e:
                logger.error(f"‚ùå Error con IA avanzada: {e}. Usando fallback...")
        
        # PRIORIDAD 2: Sentence Transformers
        if not self.model_loaded:
            logger.warning("‚ö†Ô∏è Usando an√°lisis b√°sico por falta de modelo")
            return self._analizar_grupo_basico(participaciones, tema, descripcion_tema, max_score)
        
        # An√°lisis con Sentence Transformers (m√©todo original)
        logger.info("ü§ñ Usando Sentence Transformers para an√°lisis")
        
        resultados = []
        texto_tema = f"{tema}. {descripcion_tema}"
        
        try:
            # Generar embedding del tema una sola vez
            embedding_tema = self.model.encode([texto_tema])
            
            # Evaluar cada participante
            for idx, participacion in enumerate(participaciones, 1):
                logger.info(f"üîç Evaluando {participacion['etiqueta']}...")
                resultado_individual = self._evaluar_estudiante(
                    participacion,
                    embedding_tema,
                    tema,
                    descripcion_tema
                )
                resultados.append(resultado_individual)
            
            # Calcular calificaciones finales proporcionales
            resultados = self._calcular_calificaciones_finales(resultados, max_score)
            
            logger.info(f"‚úÖ An√°lisis completado para {len(resultados)} participantes")
            
        except Exception as e:
            logger.error(f"‚ùå Error en an√°lisis de grupo: {str(e)}", exc_info=True)
            return self._analizar_grupo_basico(participaciones, tema, descripcion_tema, max_score)
        
        return resultados
    
    def _evaluar_estudiante(self, participacion, embedding_tema, tema, descripcion_tema):
        """Eval√∫a coherencia de un estudiante individual"""
        texto = participacion['texto_transcrito']
        etiqueta = participacion['etiqueta']
        
        # Validar texto m√≠nimo
        if len(texto.strip()) < 20:
            return self._resultado_sin_contenido(participacion)
        
        try:
            # 1. COHERENCIA SEM√ÅNTICA (60% de la nota)
            coherencia_semantica = self._calcular_coherencia_semantica(texto, embedding_tema)
            
            # 2. PALABRAS CLAVE (20% de la nota)
            palabras_clave = self._analizar_palabras_clave(texto, tema, descripcion_tema)
            puntaje_palabras = palabras_clave['puntaje']
            
            # 3. LONGITUD Y PROFUNDIDAD (20% de la nota)
            puntaje_profundidad = self._analizar_profundidad(texto)
            
            # CALIFICACI√ìN PONDERADA (sobre 100)
            nota_coherencia = (
                coherencia_semantica * 0.60 +  # 60%
                puntaje_palabras * 0.20 +       # 20%
                puntaje_profundidad * 0.20      # 20%
            )
            
            # Determinar nivel y observaci√≥n
            nivel, observacion = self._clasificar_coherencia(nota_coherencia, coherencia_semantica)
            
            return {
                'etiqueta': etiqueta,
                'tiempo_participacion': participacion['tiempo_participacion'],
                'texto_transcrito': texto,
                'coherencia_semantica': round(coherencia_semantica, 2),
                'palabras_clave_encontradas': palabras_clave['palabras'],
                'puntaje_palabras_clave': round(puntaje_palabras, 2),
                'puntaje_profundidad': round(puntaje_profundidad, 2),
                'nota_coherencia': round(nota_coherencia, 2),
                'nivel': nivel,
                'observacion': observacion,
                'palabras_totales': len(texto.split()),
                'caracteres': len(texto),
                'foto_url': participacion.get('foto_url')  # Incluir URL de la foto
            }
            
        except Exception as e:
            logger.error(f"‚ùå Error evaluando {etiqueta}: {str(e)}")
            return self._resultado_error(participacion)
    
    def _calcular_coherencia_semantica(self, texto, embedding_tema):
        """Calcula similitud sem√°ntica entre texto y tema"""
        embedding_estudiante = self.model.encode([texto])
        similitud = cosine_similarity(embedding_estudiante, embedding_tema)[0][0]
        
        # Convertir a porcentaje (0-100)
        # Ajustar para que valores t√≠picos (0.3-0.8) mapeen mejor a 0-100
        coherencia = float(similitud * 125)  # Factor de ajuste
        coherencia = min(100, max(0, coherencia))  # Limitar a 0-100
        
        return coherencia
    
    def _analizar_palabras_clave(self, texto, tema, descripcion):
        """Detecta palabras clave del tema en el texto del estudiante"""
        # Combinar tema y descripci√≥n para extraer m√°s palabras clave
        texto_completo_tema = f"{tema} {descripcion}".lower()
        palabras_tema = set(texto_completo_tema.split())
        palabras_texto = set(texto.lower().split())
        
        # Filtrar palabras comunes sin valor (stop words)
        palabras_comunes = {
            'el', 'la', 'los', 'las', 'un', 'una', 'unos', 'unas',
            'de', 'en', 'y', 'o', 'pero', 'por', 'para', 'con',
            'a', 'al', 'del', 'es', 'son', 'est√°', 'est√°n',
            'que', 'cual', 'como', 'se', 'su', 'sus', 'mi', 'tu',
            'te', 'me', 'le', 'les', 'nos', 'lo', 'este', 'esta'
        }
        palabras_tema = palabras_tema - palabras_comunes
        
        # Filtrar palabras muy cortas (menos de 4 letras)
        palabras_tema = {p for p in palabras_tema if len(p) >= 4}
        
        # Encontrar coincidencias
        palabras_encontradas = list(palabras_tema.intersection(palabras_texto))
        
        # Calcular puntaje
        if len(palabras_tema) > 0:
            porcentaje = (len(palabras_encontradas) / len(palabras_tema)) * 100
            # Puntaje: 100 si encuentra al menos 40% de palabras clave
            puntaje = min(porcentaje * 2.5, 100)
        else:
            puntaje = 50  # Puntaje neutral si no hay palabras clave
        
        return {
            'palabras': palabras_encontradas[:10],  # Limitar a 10 para display
            'puntaje': puntaje,
            'total_encontradas': len(palabras_encontradas),
            'total_tema': len(palabras_tema)
        }
    
    def _analizar_profundidad(self, texto):
        """Eval√∫a la profundidad del contenido basado en longitud y estructura"""
        palabras = texto.split()
        num_palabras = len(palabras)
        
        # Palabras indicadoras de profundidad y an√°lisis
        indicadores_profundidad = [
            'porque', 'debido', 'causa', 'consecuencia', 'resultado',
            'ejemplo', 'como', 'adem√°s', 'tambi√©n', 'sin embargo',
            'por lo tanto', 'en conclusi√≥n', 'finalmente', 'as√≠',
            'entonces', 'espec√≠ficamente', 'particularmente',
            'significa', 'implica', 'demuestra', 'evidencia',
            'importante', 'fundamental', 'esencial', 'clave',
            'primero', 'segundo', 'tercero', 'finalmente'
        ]
        
        texto_lower = texto.lower()
        indicadores_encontrados = sum(
            1 for indicador in indicadores_profundidad 
            if indicador in texto_lower
        )
        
        # Puntaje basado en palabras (30-50% del total)
        if num_palabras < 20:
            puntaje_base = 10
        elif num_palabras < 40:
            puntaje_base = 30
        elif num_palabras < 80:
            puntaje_base = 50
        elif num_palabras < 150:
            puntaje_base = 70
        else:
            puntaje_base = 85
        
        # Bonus por uso de conectores y palabras de an√°lisis (hasta 30% adicional)
        bonus_conectores = min(indicadores_encontrados * 3, 15)
        
        # Bonus por longitud de oraciones (se√±al de elaboraci√≥n)
        oraciones = texto.count('.') + texto.count('?') + texto.count('!')
        if oraciones > 0:
            palabras_por_oracion = num_palabras / oraciones
            if 10 <= palabras_por_oracion <= 25:  # Rango ideal
                bonus_oraciones = 5
            else:
                bonus_oraciones = 0
        else:
            bonus_oraciones = 0
        
        puntaje_total = min(puntaje_base + bonus_conectores + bonus_oraciones, 100)
        
        return puntaje_total
    
    def _clasificar_coherencia(self, nota_coherencia, coherencia_semantica):
        """Determina nivel y observaci√≥n seg√∫n el puntaje"""
        if nota_coherencia >= 80:
            nivel = "Excelente"
            observacion = "Discurso altamente coherente y bien estructurado con el tema asignado"
        elif nota_coherencia >= 70:
            nivel = "Muy Buena"
            observacion = "Muy buena relaci√≥n con el tema, aborda los puntos principales"
        elif nota_coherencia >= 60:
            nivel = "Buena"
            observacion = "Buena coherencia con el tema, cubre aspectos relevantes"
        elif nota_coherencia >= 50:
            nivel = "Regular"
            observacion = "Coherencia moderada, se desv√≠a parcialmente del tema"
        elif nota_coherencia >= 40:
            nivel = "Baja"
            observacion = "Poca coherencia con el tema asignado, varios desv√≠os"
        else:
            nivel = "Insuficiente"
            observacion = "Contenido insuficiente o muy poco relacionado con el tema"
        
        return nivel, observacion
    
    def _calcular_calificaciones_finales(self, resultados, max_score=20.0):
        """
        Calcula el porcentaje de aporte de cada estudiante
        considerando tiempo Y coherencia
        """
        # Calcular tiempo total
        tiempo_total = sum(r['tiempo_participacion'] for r in resultados)
        
        if tiempo_total == 0:
            logger.warning("‚ö†Ô∏è Tiempo total es 0, asignando valores predeterminados")
            for r in resultados:
                r['porcentaje_tiempo'] = 0
                r['porcentaje_aporte'] = 0
                r['calificacion_final'] = 0
            return resultados
        
        for resultado in resultados:
            # Porcentaje de tiempo
            porcentaje_tiempo = (resultado['tiempo_participacion'] / tiempo_total) * 100
            resultado['porcentaje_tiempo'] = round(porcentaje_tiempo, 2)
            
            # Porcentaje de aporte = tiempo √ó factor_coherencia
            # Si habl√≥ 33% del tiempo con 80% de coherencia ‚Üí aporte ajustado
            factor_coherencia = resultado['nota_coherencia'] / 100
            aporte_ponderado = porcentaje_tiempo * factor_coherencia
            
            resultado['porcentaje_aporte'] = round(aporte_ponderado, 2)
            
            # Calificaci√≥n final sobre max_score (din√°mico seg√∫n configuraci√≥n de asignaci√≥n)
            # Basada en coherencia ajustada por participaci√≥n m√≠nima
            if porcentaje_tiempo < 15:  # Menos del 15% es penalizado
                factor_penalizacion = porcentaje_tiempo / 15
            else:
                factor_penalizacion = 1.0
            
            calificacion = (resultado['nota_coherencia'] / 100) * max_score * factor_penalizacion
            resultado['calificacion_final'] = round(calificacion, 2)
        
        # Normalizar porcentajes de aporte para que sumen 100%
        suma_aportes = sum(r['porcentaje_aporte'] for r in resultados)
        if suma_aportes > 0:
            for resultado in resultados:
                resultado['porcentaje_aporte_normalizado'] = round(
                    (resultado['porcentaje_aporte'] / suma_aportes) * 100, 2
                )
        else:
            for resultado in resultados:
                resultado['porcentaje_aporte_normalizado'] = 0
        
        return resultados
    
    def _analizar_grupo_basico(self, participaciones, tema, descripcion_tema, max_score=20.0):
        """An√°lisis b√°sico sin modelo de embeddings (fallback)"""
        logger.info("üìä Usando an√°lisis b√°sico de coherencia")
        
        resultados = []
        for participacion in participaciones:
            texto = participacion['texto_transcrito']
            
            # An√°lisis b√°sico por palabras clave
            palabras_clave = self._analizar_palabras_clave(texto, tema, descripcion_tema)
            puntaje_palabras = palabras_clave['puntaje']
            
            # An√°lisis de profundidad
            puntaje_profundidad = self._analizar_profundidad(texto)
            
            # Puntaje combinado (sin similitud sem√°ntica)
            nota_coherencia = (puntaje_palabras * 0.6 + puntaje_profundidad * 0.4)
            
            nivel, observacion = self._clasificar_coherencia(nota_coherencia, puntaje_palabras)
            
            resultados.append({
                'etiqueta': participacion['etiqueta'],
                'tiempo_participacion': participacion['tiempo_participacion'],
                'texto_transcrito': texto,
                'coherencia_semantica': puntaje_palabras,
                'palabras_clave_encontradas': palabras_clave['palabras'],
                'puntaje_palabras_clave': round(puntaje_palabras, 2),
                'puntaje_profundidad': round(puntaje_profundidad, 2),
                'nota_coherencia': round(nota_coherencia, 2),
                'nivel': nivel,
                'observacion': observacion + " (an√°lisis b√°sico)",
                'palabras_totales': len(texto.split()),
                'caracteres': len(texto)
            })
        
        return self._calcular_calificaciones_finales(resultados, max_score)
    
    def _resultado_sin_contenido(self, participacion):
        """Resultado para participante sin contenido suficiente"""
        return {
            'etiqueta': participacion['etiqueta'],
            'tiempo_participacion': participacion['tiempo_participacion'],
            'texto_transcrito': participacion['texto_transcrito'],
            'coherencia_semantica': 0,
            'palabras_clave_encontradas': [],
            'puntaje_palabras_clave': 0,
            'puntaje_profundidad': 0,
            'nota_coherencia': 0,
            'nivel': "Insuficiente",
            'observacion': "Participaci√≥n muy breve o sin contenido relevante",
            'palabras_totales': len(participacion['texto_transcrito'].split()),
            'caracteres': len(participacion['texto_transcrito'])
        }
    
    def _resultado_error(self, participacion):
        """Resultado en caso de error de procesamiento"""
        return {
            'etiqueta': participacion['etiqueta'],
            'tiempo_participacion': participacion['tiempo_participacion'],
            'texto_transcrito': participacion['texto_transcrito'],
            'coherencia_semantica': 0,
            'palabras_clave_encontradas': [],
            'puntaje_palabras_clave': 0,
            'puntaje_profundidad': 0,
            'nota_coherencia': 0,
            'nivel': "Error",
            'observacion': "Error al procesar la participaci√≥n",
            'palabras_totales': 0,
            'caracteres': 0
        }
    
    def generar_resumen_grupal(self, resultados):
        """
        Genera un resumen textual del an√°lisis grupal
        
        Args:
            resultados: Lista de resultados individuales
        
        Returns:
            str: Resumen formateado en texto
        """
        if not resultados:
            return "No hay resultados para mostrar."
        
        resumen = f"üìä **EVALUACI√ìN GRUPAL - {len(resultados)} Participantes**\n\n"
        
        # Ordenar por calificaci√≥n (mayor a menor)
        resultados_ordenados = sorted(resultados, key=lambda x: x['calificacion_final'], reverse=True)
        
        for idx, r in enumerate(resultados_ordenados, 1):
            resumen += f"**{idx}. {r['etiqueta']}**\n"
            resumen += f"   üìù Calificaci√≥n: {r['calificacion_final']}/20 ({r['nivel']})\n"
            resumen += f"   ‚è±Ô∏è  Tiempo: {r['porcentaje_tiempo']:.1f}%\n"
            resumen += f"   üìà Aporte: {r['porcentaje_aporte_normalizado']:.1f}%\n"
            resumen += f"   üéØ Coherencia: {r['nota_coherencia']:.1f}/100\n"
            resumen += f"   üí¨ {r['palabras_totales']} palabras\n\n"
        
        # Estad√≠sticas generales
        promedio_coherencia = np.mean([r['nota_coherencia'] for r in resultados])
        promedio_calificacion = np.mean([r['calificacion_final'] for r in resultados])
        
        resumen += f"**üìä Estad√≠sticas del Grupo:**\n"
        resumen += f"   ‚Ä¢ Coherencia promedio: {promedio_coherencia:.1f}/100\n"
        resumen += f"   ‚Ä¢ Calificaci√≥n promedio: {promedio_calificacion:.1f}/20\n"
        
        # An√°lisis de equidad
        desviacion_tiempo = np.std([r['porcentaje_tiempo'] for r in resultados])
        if desviacion_tiempo < 10:
            resumen += f"   ‚Ä¢ ‚úÖ Participaci√≥n muy equilibrada\n"
        elif desviacion_tiempo < 20:
            resumen += f"   ‚Ä¢ ‚ö†Ô∏è  Participaci√≥n moderadamente equilibrada\n"
        else:
            resumen += f"   ‚Ä¢ ‚ùå Participaci√≥n desigual\n"
        
        return resumen

    def _analizar_con_ia_avanzada(self, participaciones, tema, descripcion_tema, max_score=20.0):
        """
        Analiza coherencia usando IA avanzada (Groq API)
        
        Este m√©todo utiliza Llama 3.3 70B para an√°lisis sem√°ntico profundo
        """
        resultados = []
        
        for participacion in participaciones:
            etiqueta = participacion['etiqueta']
            texto = participacion['texto_transcrito']
            tiempo = participacion['tiempo_participacion']
            
            logger.info(f"ü§ñ Analizando {etiqueta} con IA avanzada...")
            
            try:
                # Llamar al servicio de IA avanzada
                ai_result = self.advanced_service.analyze_participant_coherence(
                    participant_name=etiqueta,
                    transcribed_text=texto,
                    assignment_title=tema,
                    assignment_description=descripcion_tema
                )
                
                # Convertir score de 0-100 a nota de 0-max_score (din√°mico seg√∫n asignaci√≥n)
                coherence_score = ai_result['coherence_score']  # 0-100
                nota_sobre_max = (coherence_score / 100) * max_score  # 0-max_score
                
                # Construir resultado compatible con el formato existente
                resultado = {
                    'etiqueta': etiqueta,
                    'texto_transcrito': texto,
                    'nota_coherencia': coherence_score,  # 0-100
                    'calificacion_final': round(nota_sobre_max, 2),  # 0-max_score
                    'nivel': self._clasificar_nivel(nota_sobre_max),
                    'observacion': ai_result['feedback'][:200] + '...' if len(ai_result['feedback']) > 200 else ai_result['feedback'],  # Resumen corto
                    'feedback_ia_avanzada': ai_result['feedback'],  # Feedback completo de IA
                    'palabras_totales': len(texto.split()),
                    'tiempo_participacion': tiempo,
                    'porcentaje_tiempo': 0,  # Se calcula despu√©s
                    'porcentaje_aporte_normalizado': 0,  # Se calcula despu√©s
                    
                    # Compatibilidad con campos existentes
                    'coherencia_semantica': coherence_score,
                    'palabras_clave_encontradas': ai_result.get('key_concepts_covered', []),
                    'puntaje_palabras_clave': coherence_score,  # Aproximaci√≥n
                    'puntaje_profundidad': coherence_score,  # Aproximaci√≥n
                    'foto_url': participacion.get('foto_url'),
                    
                    # Detalles de IA avanzada
                    'ai_powered': True,
                    'details': ai_result['details'],
                    'strengths': ai_result.get('strengths', []),
                    'improvements': ai_result.get('improvements', []),
                    'key_concepts_covered': ai_result.get('key_concepts_covered', []),
                    'missing_elements': ai_result.get('missing_elements', [])
                }
                
                resultados.append(resultado)
                logger.info(f"‚úÖ {etiqueta}: {coherence_score:.1f}% coherencia")
                
            except Exception as e:
                logger.error(f"‚ùå Error analizando {etiqueta} con IA: {e}")
                # Fallback a an√°lisis b√°sico para este participante
                resultado_basico = self._analizar_participante_basico(
                    participacion, tema, descripcion_tema
                )
                resultados.append(resultado_basico)
        
        # Calcular porcentajes relativos
        if resultados:
            tiempo_total = sum(r['tiempo_participacion'] for r in resultados)
            for resultado in resultados:
                resultado['porcentaje_tiempo'] = (
                    (resultado['tiempo_participacion'] / tiempo_total * 100) 
                    if tiempo_total > 0 else 0
                )
                resultado['porcentaje_aporte_normalizado'] = resultado['porcentaje_tiempo']
        
        return resultados
    
    def _clasificar_nivel(self, nota):
        """Clasifica el nivel de desempe√±o seg√∫n la nota (0-20)"""
        if nota >= 18:
            return "Excelente"
        elif nota >= 15:
            return "Muy Bueno"
        elif nota >= 13:
            return "Bueno"
        elif nota >= 11:
            return "Regular"
        else:
            return "Insuficiente"
    
    def _analizar_participante_basico(self, participacion, tema, descripcion_tema):
        """An√°lisis b√°sico de un participante (fallback)"""
        etiqueta = participacion['etiqueta']
        texto = participacion['texto_transcrito']
        tiempo = participacion['tiempo_participacion']
        
        # An√°lisis muy b√°sico basado en longitud y palabras clave
        palabras = texto.lower().split()
        palabras_tema = tema.lower().split()
        
        coincidencias = sum(1 for p in palabras if p in palabras_tema)
        coherencia_basica = min(100, (coincidencias / max(len(palabras_tema), 1)) * 100)
        
        nota_20 = (coherencia_basica / 100) * 20
        
        return {
            'etiqueta': etiqueta,
            'nota_coherencia': coherencia_basica,
            'calificacion_final': round(nota_20, 2),
            'nivel': self._clasificar_nivel(nota_20),
            'feedback': f"An√°lisis b√°sico: {coincidencias} coincidencias con el tema.",
            'palabras_totales': len(palabras),
            'tiempo_participacion': tiempo,
            'porcentaje_tiempo': 0,
            'porcentaje_aporte_normalizado': 0,
            'ai_powered': False
        }
