"""
Servicio de an√°lisis de coherencia con IA avanzada usando Groq API
==================================================================
Utiliza Llama 3.3 70B para an√°lisis sem√°ntico profundo de coherencia
en exposiciones acad√©micas.

Analiza:
- Coherencia tem√°tica con las instrucciones de la asignaci√≥n
- Relevancia del contenido transcrito
- Profundidad y calidad del an√°lisis
- Estructura y organizaci√≥n del discurso

Sistema de rotaci√≥n autom√°tica de API keys incluido.
"""

from groq import Groq
from django.conf import settings
import logging
import json
import re

logger = logging.getLogger(__name__)


class AdvancedCoherenceService:
    """
    An√°lisis de coherencia con IA avanzada usando Groq API (Llama 3.3 70B)
    
    Proporciona evaluaci√≥n detallada de la coherencia entre:
    - Las instrucciones/descripci√≥n de la asignaci√≥n
    - El contenido transcrito por Whisper
    - El tema general de la exposici√≥n
    
    Incluye rotaci√≥n autom√°tica de API keys para evitar rate limits.
    """
    
    def __init__(self):
        """Inicializa el servicio con el gestor de API keys de Groq"""
        from .groq_key_manager import get_groq_key_manager
        
        self.key_manager = get_groq_key_manager()
        self.config = settings.COHERENCE_CONFIG
        self.client = None  # Se inicializa din√°micamente
        
        # Verificar que hay al menos una key disponible
        current_key = self.key_manager.get_current_key()
        if not current_key:
            raise ValueError(
                "‚ö†Ô∏è No hay API keys de Groq configuradas. "
                "Configura GROQ_API_KEY_1, GROQ_API_KEY_2, etc. en .env"
            )
        
        logger.info(f"‚úÖ AdvancedCoherenceService inicializado con {len(self.key_manager.keys)} API keys")
    
    def _get_client(self) -> Groq:
        """
        Obtiene un cliente de Groq con la API key actual.
        
        Se actualiza din√°micamente seg√∫n la rotaci√≥n de keys.
        """
        current_key = self.key_manager.get_current_key()
        if not current_key:
            raise ValueError("No hay API keys disponibles actualmente")
        
        # Crear nuevo cliente con la key actual
        return Groq(api_key=current_key)
    
    def analyze_participant_coherence(
        self,
        participant_name: str,
        transcribed_text: str,
        assignment_title: str,
        assignment_description: str,
        assignment=None
    ) -> dict:
        """
        Analiza la coherencia de un participante individual.
        
        Args:
            participant_name: Nombre/etiqueta del participante
            transcribed_text: Texto transcrito por Whisper de este participante
            assignment_title: T√≠tulo de la asignaci√≥n
            assignment_description: Descripci√≥n completa de la asignaci√≥n
            assignment: Objeto Assignment completo (opcional, para obtener configuraci√≥n de IA)
        
        Returns:
            dict con:
                - coherence_score: float (0-100)
                - feedback: str (retroalimentaci√≥n detallada)
                - details: dict (desglose por criterios)
                - strengths: list (puntos fuertes)
                - improvements: list (√°reas de mejora)
        """
        # Validar entrada
        if not transcribed_text or len(transcribed_text.strip()) < 20:
            return self._insufficient_text_response(participant_name)
        
        # Obtener nivel de estrictez con orden de prioridad:
        # 1. Nivel espec√≠fico del assignment (si est√° configurado)
        # 2. Nivel global del teacher (si est√° disponible)
        # 3. Default 'moderate'
        strictness_level = 'moderate'  # Default
        
        if assignment:
            # Prioridad 1: Nivel espec√≠fico del assignment
            if assignment.strictness_level:
                strictness_level = assignment.strictness_level
                logger.info(f"üìä Usando nivel de estrictez del assignment: {strictness_level}")
            # Prioridad 2: Nivel global del teacher
            elif assignment.course and assignment.course.teacher:
                try:
                    from apps.presentaciones.models import AIConfiguration
                    config = AIConfiguration.objects.filter(teacher=assignment.course.teacher).first()
                    if config:
                        strictness_level = config.strictness_level
                        logger.info(f"üìä Usando nivel de estrictez global del teacher: {strictness_level}")
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è No se pudo obtener configuraci√≥n de IA: {e}")
        
        # Intentar con rotaci√≥n autom√°tica de keys
        max_retries = len(self.key_manager.keys)
        
        for attempt in range(max_retries):
            try:
                # Obtener cliente con key actual
                client = self._get_client()
                current_key = self.key_manager.get_current_key()
                
                # Construir prompt optimizado
                prompt = self._build_evaluation_prompt(
                    participant_name=participant_name,
                    transcribed_text=transcribed_text,
                    assignment_title=assignment_title,
                    assignment_description=assignment_description,
                    strictness_level=strictness_level
                )
                
                # Llamar a Groq API
                logger.info(f"ü§ñ Analizando coherencia con Groq para: {participant_name} (intento {attempt + 1}/{max_retries})")
                logger.info(f"üìù Texto a analizar: {len(transcribed_text)} caracteres")
                
                response = client.chat.completions.create(
                    model=self.config['model'],
                    messages=[
                        {
                            "role": "system",
                            "content": self._get_system_prompt()
                        },
                        {
                            "role": "user",
                            "content": prompt
                        }
                    ],
                    temperature=self.config['temperature'],
                    max_tokens=self.config['max_tokens'],
                    timeout=self.config.get('timeout', 45)
                )
                
                # Parsear respuesta de la IA
                ai_response = response.choices[0].message.content
                result = self._parse_ai_response(ai_response, participant_name)
                
                logger.info(
                    f"‚úÖ An√°lisis completado para {participant_name}: "
                    f"{result['coherence_score']:.1f}% de coherencia"
                )
                
                return result
                
            except Exception as e:
                error_message = str(e).lower()
                
                # Detectar errores de rate limit
                if 'rate_limit' in error_message or 'quota' in error_message or '429' in error_message:
                    logger.warning(f"‚ö†Ô∏è Rate limit alcanzado: {e}")
                    self.key_manager.mark_key_as_failed(current_key, f"Rate limit: {e}")
                    
                    # Intentar con siguiente key
                    if attempt < max_retries - 1:
                        logger.info(f"üîÑ Reintentando con siguiente API key...")
                        continue
                    
                # Otros errores
                logger.error(f"‚ùå Error en an√°lisis con Groq: {str(e)}", exc_info=True)
                
                # Si es el √∫ltimo intento, devolver fallback
                if attempt == max_retries - 1:
                    return self._fallback_response(participant_name, str(e))
        
        # Si llegamos aqu√≠, todas las keys fallaron
        return self._fallback_response(participant_name, "Todas las API keys agotadas")
    
    def _get_strictness_instructions(self, strictness_level: str) -> str:
        """
        Retorna las instrucciones de evaluaci√≥n seg√∫n el nivel de estrictez configurado.
        
        Args:
            strictness_level: 'strict', 'moderate', o 'lenient'
        
        Returns:
            str: Instrucciones espec√≠ficas para la IA seg√∫n el nivel
        """
        instructions = {
            'strict': """
üî¥ NIVEL DE EVALUACI√ìN: ESTRICTO

CRITERIOS DE CALIFICACI√ìN:
- Requiere dominio COMPLETO y PROFUNDO del tema
- Penaliza fuertemente imprecisiones, falta de profundidad o contenido superficial
- Exige estructura clara, ejemplos concretos y datos espec√≠ficos
- Solo calificaciones altas (85-100) para exposiciones EXCEPCIONALES con dominio total
- Calificaciones medias (70-84) para presentaciones correctas pero no excepcionales
- Calificaciones bajas (<70) si hay errores conceptuales o falta de profundidad

S√â MUY EXIGENTE: El estudiante debe demostrar comprensi√≥n profunda y manejo experto del tema.""",
            
            'moderate': """
üü° NIVEL DE EVALUACI√ìN: MODERADO (RECOMENDADO)

CRITERIOS DE CALIFICACI√ìN:
- Califica 70-95% para presentaciones bien desarrolladas que cubran el tema adecuadamente
- Califica 85-95% para presentaciones sobresalientes con buen dominio
- Busca un balance entre exigencia acad√©mica y comprensi√≥n razonable
- Valora la profundidad y relevancia del contenido
- Penaliza divagaciones importantes o errores conceptuales graves
- Reconoce el esfuerzo cuando hay comprensi√≥n b√°sica s√≥lida

S√â JUSTO: Eval√∫a objetivamente el cumplimiento de las instrucciones con criterio balanceado.""",
            
            'lenient': """
üü¢ NIVEL DE EVALUACI√ìN: SUAVE

CRITERIOS DE CALIFICACI√ìN:
- Califica 70-80% si demuestra comprensi√≥n B√ÅSICA del tema
- Califica 85-95% si el contenido es relevante y muestra esfuerzo
- Valora el esfuerzo, la participaci√≥n y el intento de cumplir las instrucciones
- Enf√≥cate en reforzar lo POSITIVO m√°s que en se√±alar deficiencias
- S√© tolerante con imprecisiones menores si la idea general es correcta
- Reconoce cualquier conexi√≥n v√°lida con el tema asignado

S√â COMPRENSIVO: Busca aspectos positivos y da cr√©dito por el esfuerzo demostrado."""
        }
        
        return instructions.get(strictness_level, instructions['moderate'])
    
    def _get_system_prompt(self) -> str:
        """Prompt del sistema que define el rol de la IA"""
        return """Eres un evaluador acad√©mico experto especializado en:
- An√°lisis de coherencia y relevancia en exposiciones orales
- Evaluaci√≥n de comprensi√≥n y profundidad de contenido
- Retroalimentaci√≥n constructiva y espec√≠fica para estudiantes

Tu objetivo es evaluar objetivamente si lo que el estudiante dijo (seg√∫n la transcripci√≥n) 
es coherente con las instrucciones de la asignaci√≥n que se le dio.

IMPORTANTE:
- S√© justo pero exigente
- Proporciona feedback espec√≠fico y √∫til
- Detecta si el estudiante comprendi√≥ realmente el tema
- Identifica si el contenido es relevante o si divaga
- Reconoce tanto fortalezas como √°reas de mejora"""
    
    def _build_evaluation_prompt(
        self,
        participant_name: str,
        transcribed_text: str,
        assignment_title: str,
        assignment_description: str,
        strictness_level: str = 'moderate'
    ) -> str:
        """Construye el prompt de evaluaci√≥n con toda la informaci√≥n"""
        
        # Truncar texto si es muy largo (para no exceder l√≠mites de tokens)
        max_text_length = 4000
        if len(transcribed_text) > max_text_length:
            transcribed_text = transcribed_text[:max_text_length] + "..."
            logger.warning(f"‚ö†Ô∏è Texto truncado a {max_text_length} caracteres")
        
        # Definir instrucciones seg√∫n nivel de estrictez
        strictness_instructions = self._get_strictness_instructions(strictness_level)
        
        return f"""
Eval√∫a la coherencia entre lo que el estudiante dijo y las instrucciones de la asignaci√≥n.

{strictness_instructions}

‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
üìã ASIGNACI√ìN DADA AL ESTUDIANTE
‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ

**T√çTULO:** {assignment_title}

**INSTRUCCIONES/DESCRIPCI√ìN:**
{assignment_description if assignment_description else "No se proporcion√≥ descripci√≥n espec√≠fica"}

‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
üé§ LO QUE EL ESTUDIANTE DIJO (Transcripci√≥n de Whisper)
‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ

**PARTICIPANTE:** {participant_name}

**TRANSCRIPCI√ìN:**
"{transcribed_text}"

‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
üìä CRITERIOS DE EVALUACI√ìN
‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ

Eval√∫a de 0-100 cada criterio:

1. **COHERENCIA TEM√ÅTICA (40%):**
   - ¬øAborda el tema/instrucciones de la asignaci√≥n?
   - ¬øSe mantiene enfocado o divaga?
   - ¬øEl contenido es pertinente?

2. **COMPRENSI√ìN Y PROFUNDIDAD (30%):**
   - ¬øDemuestra comprensi√≥n del tema?
   - ¬øIncluye detalles, ejemplos o datos?
   - ¬øEs superficial o profundo?

3. **RELEVANCIA DEL CONTENIDO (20%):**
   - ¬øLa informaci√≥n aportada es valiosa?
   - ¬øResponde a lo que se ped√≠a?
   - ¬øEvita contenido irrelevante?

4. **ESTRUCTURA Y CLARIDAD (10%):**
   - ¬øEl discurso tiene estructura l√≥gica?
   - ¬øLas ideas se expresan claramente?
   - ¬øHay fluidez en la exposici√≥n?

‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
üìù FORMATO DE RESPUESTA REQUERIDO
‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ

Responde EXACTAMENTE en este formato JSON (sin texto adicional):

```json
{{
  "thematic_coherence": 85.0,
  "depth_understanding": 75.0,
  "content_relevance": 90.0,
  "structure_clarity": 80.0,
  "overall_coherence": 82.5,
  "feedback": "An√°lisis breve (150-250 palabras) que explique la calificaci√≥n, destacando qu√© tan bien cumpli√≥ con las instrucciones de la asignaci√≥n.",
  "strengths": [
    "Punto fuerte espec√≠fico 1",
    "Punto fuerte espec√≠fico 2",
    "Punto fuerte espec√≠fico 3"
  ],
  "improvements": [
    "Sugerencia concreta 1",
    "Sugerencia concreta 2",
    "Sugerencia concreta 3"
  ],
  "key_concepts_covered": [
    "Concepto clave 1 mencionado",
    "Concepto clave 2 mencionado"
  ],
  "missing_elements": [
    "Elemento que falt√≥ seg√∫n las instrucciones",
    "Otro aspecto no abordado"
  ]
}}
```

IMPORTANTE: 
- S√© espec√≠fico y objetivo
- Basa tu evaluaci√≥n en la coherencia entre instrucciones y transcripci√≥n
- El feedback debe ser constructivo y √∫til para el estudiante
"""
    
    def _parse_ai_response(self, response_text: str, participant_name: str) -> dict:
        """
        Parsea la respuesta JSON de la IA y extrae las calificaciones.
        """
        try:
            # Intentar extraer JSON del texto
            json_match = re.search(r'\{[\s\S]*\}', response_text)
            
            if not json_match:
                raise ValueError("No se encontr√≥ JSON en la respuesta")
            
            data = json.loads(json_match.group())
            
            # Extraer puntuaciones
            thematic = float(data.get('thematic_coherence', 70))
            depth = float(data.get('depth_understanding', 70))
            relevance = float(data.get('content_relevance', 70))
            structure = float(data.get('structure_clarity', 70))
            
            # Calcular score final ponderado
            overall_score = (
                thematic * 0.40 +
                depth * 0.30 +
                relevance * 0.20 +
                structure * 0.10
            )
            
            # Validar que est√© en rango 0-100
            overall_score = max(0, min(100, overall_score))
            
            return {
                'coherence_score': round(overall_score, 1),
                'feedback': data.get('feedback', 'An√°lisis completado por IA'),
                'details': {
                    'thematic_coherence': thematic,
                    'depth_understanding': depth,
                    'content_relevance': relevance,
                    'structure_clarity': structure
                },
                'strengths': data.get('strengths', []),
                'improvements': data.get('improvements', []),
                'key_concepts_covered': data.get('key_concepts_covered', []),
                'missing_elements': data.get('missing_elements', []),
                'ai_powered': True,
                'participant_name': participant_name
            }
            
        except json.JSONDecodeError as e:
            logger.error(f"‚ùå Error parseando JSON: {e}")
            logger.debug(f"Respuesta recibida: {response_text[:500]}")
            
            # Intentar extraer score del texto plano
            score_match = re.search(r'(\d+\.?\d*)\s*[%/]', response_text)
            score = float(score_match.group(1)) if score_match else 70.0
            
            return {
                'coherence_score': min(100, score),
                'feedback': response_text[:500],
                'details': {
                    'thematic_coherence': score,
                    'depth_understanding': score,
                    'content_relevance': score,
                    'structure_clarity': score
                },
                'strengths': ['An√°lisis completado'],
                'improvements': ['Ver feedback para detalles'],
                'ai_powered': True,
                'participant_name': participant_name
            }
        
        except Exception as e:
            logger.error(f"‚ùå Error inesperado parseando respuesta: {e}")
            raise
    
    def _insufficient_text_response(self, participant_name: str) -> dict:
        """Respuesta cuando el texto es insuficiente para an√°lisis"""
        return {
            'coherence_score': 0.0,
            'feedback': (
                f"‚ö†Ô∏è {participant_name} tiene texto insuficiente para an√°lisis "
                f"(menos de 20 caracteres). Esto puede indicar que no particip√≥ "
                f"verbalmente o que la transcripci√≥n fall√≥."
            ),
            'details': {
                'thematic_coherence': 0.0,
                'depth_understanding': 0.0,
                'content_relevance': 0.0,
                'structure_clarity': 0.0
            },
            'strengths': [],
            'improvements': ['Participar m√°s activamente en la exposici√≥n oral'],
            'key_concepts_covered': [],
            'missing_elements': ['Contenido verbal'],
            'ai_powered': False,
            'participant_name': participant_name
        }
    
    def _fallback_response(self, participant_name: str, error_message: str) -> dict:
        """Respuesta de fallback cuando falla la API"""
        return {
            'coherence_score': 0.0,
            'feedback': (
                f"‚ùå No se pudo analizar la coherencia de {participant_name} "
                f"con IA avanzada. Error: {error_message}. "
                f"Por favor, revisa la configuraci√≥n de GROQ_API_KEY."
            ),
            'details': {
                'thematic_coherence': 0.0,
                'depth_understanding': 0.0,
                'content_relevance': 0.0,
                'structure_clarity': 0.0
            },
            'strengths': [],
            'improvements': [],
            'key_concepts_covered': [],
            'missing_elements': [],
            'ai_powered': False,
            'participant_name': participant_name,
            'error': error_message
        }
    
    def batch_analyze(self, participants_data: list, assignment_info: dict) -> list:
        """
        Analiza m√∫ltiples participantes en batch.
        
        Args:
            participants_data: Lista de dicts con 'name' y 'transcription'
            assignment_info: Dict con 'title' y 'description'
        
        Returns:
            Lista de resultados de an√°lisis
        """
        results = []
        
        assignment_title = assignment_info.get('title', 'Sin t√≠tulo')
        assignment_description = assignment_info.get('description', '')
        
        for participant in participants_data:
            result = self.analyze_participant_coherence(
                participant_name=participant['name'],
                transcribed_text=participant['transcription'],
                assignment_title=assignment_title,
                assignment_description=assignment_description
            )
            results.append(result)
        
        return results
    
    @staticmethod
    def is_available() -> bool:
        """Verifica si el servicio est√° disponible (API key configurada)"""
        return bool(settings.GROQ_API_KEY)
